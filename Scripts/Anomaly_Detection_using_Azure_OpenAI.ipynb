{"cells":[{"cell_type":"markdown","source":["### Install packages"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f5f8b248-2972-4df4-ad7f-3e2d4128d9ba"},{"cell_type":"code","source":["%pip install openai==1.12.0"],"outputs":[],"execution_count":null,"metadata":{},"id":"654c69a2-bdc8-4dbd-855a-7be96041d672"},{"cell_type":"markdown","source":["### Required packages"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"b1f6884c-2f65-4e60-98ca-2afd61b53ba1"},{"cell_type":"code","source":["import openai\n","from openai import AzureOpenAI\n","import json\n","from IPython import get_ipython\n","from IPython.terminal.interactiveshell import TerminalInteractiveShell\n","import uuid\n","import mlflow\n","\n","from pyspark.sql import functions as F\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.sql.types import *\n","from pyspark.ml import Pipeline\n","\n","from synapse.ml.isolationforest import *\n","\n","from synapse.ml.explainers import *\n","\n","%matplotlib inline\n","\n","from pyspark.sql import functions as F\n","from pyspark.sql.functions import col\n","from pyspark.sql.types import IntegerType, DoubleType"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2024-03-03T20:13:57.9755455Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"64afec1c-46e5-4726-81f7-c5b10654c8ea"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"23ae6e46-de9c-4069-b2af-7904b67142b6"},{"cell_type":"markdown","source":["### Set up Azure OpenAI connection\n","###### Reference: https://community.fabric.microsoft.com/t5/Hack-Together/Fabric-cant-import-AzureOpenAI/m-p/3703267#M66"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"3899873d-527a-4433-8de4-0e1fe17c6a21"},{"cell_type":"code","source":["client = AzureOpenAI(\n","    azure_endpoint=\"https://polite-ground-030dc3103.4.azurestaticapps.net/api/v1\",\n","    api_key=\"e62519ec-e5a9-477e-815a-93cd4546119c\",\n","    api_version=\"2023-09-01-preview\",\n",")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2024-03-03T20:13:58.18058Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"f75914ad-d704-467c-8132-b0f0bd55ab11"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"e25c2a4b-6db7-4736-b0e7-a0030cca9652"},{"cell_type":"code","source":["# Assuming df is your DataFrame loaded from the delta format\n","df = spark.read.format(\"delta\").load(\"abfss://MS_Fabric_Hackathon@onelake.dfs.fabric.microsoft.com/Hackathon.Lakehouse/Tables/Fact_Sales\")\n","df.dtypes"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"89f826f0-d027-4763-9288-0f8255419295"},{"cell_type":"markdown","source":["### Get Data"],"metadata":{},"id":"123ddb54"},{"cell_type":"code","source":["df = spark.read.format(\"delta\").load(\"abfss://MS_Fabric_Hackathon@onelake.dfs.fabric.microsoft.com/Hackathon.Lakehouse/Tables/Fact_Sales\")\n","\n","# Ensure 'Quantity' and 'Unit_Price' are treated as numeric types\n","df = df.withColumn(\"Quantity\", F.col(\"Quantity\").cast(IntegerType())) \\\n","       .withColumn(\"Unit_Price\", F.col(\"Unit_Price\").cast(FloatType()))\n","\n","# Perform aggregation\n","df = df.groupBy(\"Date\") \\\n","    .agg(\n","        F.sum(\"Quantity\").alias(\"Quantity\"),  # Sum of Quantity\n","        (F.sum(F.col(\"Quantity\") * F.col(\"Unit_Price\")) / F.sum(\"Quantity\")).alias(\"Unit_Price\")  # Average Price calculation\n","    )\n","\n","# Cast columns as needed\n","df_adjusted = (\n","    df.orderBy(\"Date\")\n","    .withColumn(\"Date\", col(\"Date\").cast(DateType()))\n","    .withColumn(\"Quantity\", col(\"Quantity\").cast(IntegerType()))\n","    .withColumn(\"Unit_Price\", col(\"Unit_Price\").cast(FloatType()))\n","    .select(\n","        \"Date\", \n","        \"Quantity\", \n","        \"Unit_Price\"\n","    )\n",")\n","\n","# Convert Spark DataFrame to Pandas DataFrame\n","pd_df_adjusted = df_adjusted.toPandas()\n","\n","pd_df_adjusted"],"outputs":[],"execution_count":null,"metadata":{},"id":"b660fd4b"},{"cell_type":"markdown","source":["### Create prompt"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"995a39e2-cb12-406d-845a-a56e55a5aacb"},{"cell_type":"code","source":["# Prompt is a combination of 3 parts:\n","\n","prompt_1 = \"Given this data: \"\n","prompt_2 = pd_df_adjusted\n","prompt_3 = \"\"\"\n","Please provide the code to run an Isolation Forest model with the parameters below.\n","\n","contamination=0.1, \n","n_estimators=16,\n","max_samples=210, \n","max_features=1.0\n","trainingStartTime = \"2023-01-01\"\n","trainingEndTime = \"2023-07-31\"\n","inferenceStartTime = \"2023-08-01\"\n","inferenceEndTime = \"2023-08-31\"\n","\n","Only provide the python code in your response, please don't include any words different from the code.Please exclude any comments in the response, just provide the code\n","Please ensure all arrays provided are of the same length\n","Please use the data from the dataframe pd_df_adjusted provided in the prompt, do not try to load or add other data.\n","To run the model, split the data for training and test, according to the start and end times provided. Make sure to use and define the parameters detailed \n","Please store the model results in predictions with \n","\n","\"\"\"\n","\n","# Combine the 3 into a single text\n","PROMPT = f\"{prompt_1}\\n\\n{prompt_2}\\n\\n{prompt_3}\"\n","\n","print(PROMPT)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2024-03-03T20:13:58.8640963Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"4ad94174-085b-4b1d-848c-9d0403a91e67"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Given this data: \n\n           Date  Quantity  Unit_Price\n0    2023-01-01      4893   50.592808\n1    2023-01-02      4642   50.592224\n2    2023-01-03      4832   49.851822\n3    2023-01-04      4726   49.725010\n4    2023-01-05      4859   48.917988\n..          ...       ...         ...\n360  2023-12-27      4574   48.591583\n361  2023-12-28      4649   49.971371\n362  2023-12-29      4323   51.576405\n363  2023-12-30      4674   49.034725\n364  2023-12-31      4476   49.054333\n\n[365 rows x 3 columns]\n\n\nPlease provide the code to run an Isolation Forest model with the parameters below.\n\ncontamination=0.1, \nn_estimators=16,\nmax_samples=210, \nmax_features=1.0\ntrainingStartTime = \"2023-01-01\"\ntrainingEndTime = \"2023-07-31\"\ninferenceStartTime = \"2023-08-01\"\ninferenceEndTime = \"2023-08-31\"\n\nOnly provide the python code in your response, please don't include any words different from the code.Please exclude any comments in the response, just provide the code\nPlease ensure all arrays provided are of the same length\nPlease use the data from the dataframe pd_df_adjusted provided in the prompt, do not try to load or add other data.\nTo run the model, split the data for training and test, according to the start and end times provided. Make sure to use and define the parameters detailed \nPlease store the model results in predictions with \n\n\n"]}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"08542df2-f19b-42ac-98e0-8a99ff932bcc"},{"cell_type":"markdown","source":["### Get AzureOpenAI response"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"94256722-a07e-4786-9f0d-738e95c098eb"},{"cell_type":"code","source":["# Run using AzureOpenAI - Select the model and temperature\n","MESSAGES = []\n","MESSAGES.append({\"role\": \"user\", \"content\": PROMPT})\n","completion = client.chat.completions.create(\n","    # model and temperature adjusted as suggested here: https://www.reddit.com/r/ChatGPTCoding/comments/12i6k06/best_temperature_for_gpt4_api_to_get_quality/\n","    model=\"gpt-4\", messages=MESSAGES, temperature=0.1)\n","response = completion.choices[0].message.content\n","print(response)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2024-03-03T20:13:59.1657677Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"269a1919-f4ca-451d-a612-045b3644f7f8"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["import pandas as pd\nfrom sklearn.ensemble import IsolationForest\n\n# Define parameters\ncontamination=0.1\nn_estimators=16\nmax_samples=210\nmax_features=1.0\ntrainingStartTime = \"2023-01-01\"\ntrainingEndTime = \"2023-07-31\"\ninferenceStartTime = \"2023-08-01\"\ninferenceEndTime = \"2023-08-31\"\n\n# Convert Date column to datetime\npd_df_adjusted['Date'] = pd.to_datetime(pd_df_adjusted['Date'])\n\n# Split data into training and test sets\ntraining_data = pd_df_adjusted[(pd_df_adjusted['Date'] >= trainingStartTime) & (pd_df_adjusted['Date'] <= trainingEndTime)]\ntest_data = pd_df_adjusted[(pd_df_adjusted['Date'] >= inferenceStartTime) & (pd_df_adjusted['Date'] <= inferenceEndTime)]\n\n# Define features and target\nX_train = training_data[['Quantity', 'Unit_Price']]\nX_test = test_data[['Quantity', 'Unit_Price']]\n\n# Initialize and fit the model\nmodel = IsolationForest(contamination=contamination, n_estimators=n_estimators, max_samples=max_samples, max_features=max_features)\nmodel.fit(X_train)\n\n# Make predictions\npredictions = model.predict(X_test)\n"]}],"execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"a3a7d109-44cd-4b8d-93e5-f3eb7026658b"},{"cell_type":"markdown","source":["### Execute response"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f61ba2c8-846e-425a-8e60-d405b4c8f6ca"},{"cell_type":"code","source":["cleaned_response = response.replace(\"python\\n\", \"\").replace(\"\", \"\")\n","cleaned_response = cleaned_response.replace(\"```\", \"\")\n","\n","print(cleaned_response)\n","\n","exec(cleaned_response)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2024-03-03T20:13:59.3242228Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"d9a99a0a-831b-458c-b70e-9805819cc2b3"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["import pandas as pd\nfrom sklearn.ensemble import IsolationForest\n\n# Define parameters\ncontamination=0.1\nn_estimators=16\nmax_samples=210\nmax_features=1.0\ntrainingStartTime = \"2023-01-01\"\ntrainingEndTime = \"2023-07-31\"\ninferenceStartTime = \"2023-08-01\"\ninferenceEndTime = \"2023-08-31\"\n\n# Convert Date column to datetime\npd_df_adjusted['Date'] = pd.to_datetime(pd_df_adjusted['Date'])\n\n# Split data into training and test sets\ntraining_data = pd_df_adjusted[(pd_df_adjusted['Date'] >= trainingStartTime) & (pd_df_adjusted['Date'] <= trainingEndTime)]\ntest_data = pd_df_adjusted[(pd_df_adjusted['Date'] >= inferenceStartTime) & (pd_df_adjusted['Date'] <= inferenceEndTime)]\n\n# Define features and target\nX_train = training_data[['Quantity', 'Unit_Price']]\nX_test = test_data[['Quantity', 'Unit_Price']]\n\n# Initialize and fit the model\nmodel = IsolationForest(contamination=contamination, n_estimators=n_estimators, max_samples=max_samples, max_features=max_features)\nmodel.fit(X_train)\n\n# Make predictions\npredictions = model.predict(X_test)\n"]},{"output_type":"stream","name":"stderr","text":["2024-03-03:20:14:44,302 WARNING  [tracking_store.py:153] log_inputs not supported\n"]},{"output_type":"display_data","data":{"application/vnd.mlflow.run-widget+json":{"info":{"artifact_uri":"sds://onelakesouthcentralus.pbidedicated.windows.net/4c4664f3-622d-4959-933a-efeec33fe813/668cf50b-9c53-4e74-ba58-4ddf8eeb4980/f1a82f0c-b0a0-4596-96ca-c7eb148b1640/artifacts","end_time":1709496888,"experiment_id":"330f7ba7-a9f0-4e25-bb33-0ad24d3e759b","lifecycle_stage":"active","run_id":"f1a82f0c-b0a0-4596-96ca-c7eb148b1640","run_name":"","run_uuid":"f1a82f0c-b0a0-4596-96ca-c7eb148b1640","start_time":1709496884,"status":"FINISHED","user_id":"7ebfac85-3ebb-440f-a743-e52052051f6a"},"data":{"metrics":{},"params":{"bootstrap":"False","contamination":"0.1","max_features":"1.0","max_samples":"210","n_estimators":"16","n_jobs":"None","random_state":"None","verbose":"0","warm_start":"False"},"tags":{"mlflow.user":"4b3a56ea-6f42-450e-b7c3-fb2932c7ac32","synapseml.notebook.artifactId":"ab13a139-ac3e-446d-82e4-2e21a9776bff","synapseml.user.name":"Manrique Montealegre","synapseml.user.id":"597a1798-fcba-4ec7-8757-aab93c654586","synapseml.livy.id":"931e2c35-8df9-4815-901b-104b50a12236","mlflow.autologging":"sklearn","estimator_name":"IsolationForest","estimator_class":"sklearn.ensemble._iforest.IsolationForest","mlflow.rootRunId":"f1a82f0c-b0a0-4596-96ca-c7eb148b1640","mlflow.runName":"upbeat_net_kglvvy2r","synapseml.experimentName":"Find_Anomalies_Azure_OpenAI","synapseml.experiment.artifactId":"668cf50b-9c53-4e74-ba58-4ddf8eeb4980"}},"inputs":{"dataset_inputs":[]}}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["2024-03-03:20:14:48,210 WARNING  [tracking_store.py:153] log_inputs not supported\n"]}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"58b59924-86af-4bcc-a86a-ab825f0aca60"},{"cell_type":"code","source":["# Add predictions to the test_data DataFrame\n","test_data['Anomaly'] = predictions\n","\n","# Convert anomaly labels from -1 (outlier) and 1 (inlier) to a more readable format\n","test_data['Anomaly'] = test_data['Anomaly'].map({-1: 'Outlier', 1: 'Inlier'})\n","\n","# Display the test_data DataFrame with the added Anomaly column\n","print(test_data)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"state":"waiting","livy_statement_state":null,"queued_time":"2024-03-03T20:29:12.7731458Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"72990db6-a8a0-4581-acb3-281c629b7543"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["          Date  Quantity  Unit_Price  Anomaly\n212 2023-08-01      4428   49.069489   Inlier\n213 2023-08-02      4224   48.077393  Outlier\n214 2023-08-03      4571   49.976353   Inlier\n215 2023-08-04      4935   51.300648  Outlier\n216 2023-08-05      4317   50.990826   Inlier\n217 2023-08-06      4234   50.084789   Inlier\n218 2023-08-07      4548   50.882629   Inlier\n219 2023-08-08      4787   50.120033   Inlier\n220 2023-08-09      4468   48.766651   Inlier\n221 2023-08-10      4267   48.059292  Outlier\n222 2023-08-11      4893   51.206539  Outlier\n223 2023-08-12      4408   48.359188   Inlier\n224 2023-08-13      4159   50.247944  Outlier\n225 2023-08-14      4407   49.460243   Inlier\n226 2023-08-15      4667   51.245384   Inlier\n227 2023-08-16      4646   50.199764   Inlier\n228 2023-08-17      4816   50.666508   Inlier\n229 2023-08-18      4457   49.744469   Inlier\n230 2023-08-19      4731   50.206150   Inlier\n231 2023-08-20      4442   50.660851   Inlier\n232 2023-08-21      4372   47.902767   Inlier\n233 2023-08-22      4234   49.975296   Inlier\n234 2023-08-23      4629   48.316074   Inlier\n235 2023-08-24      4667   49.469444   Inlier\n236 2023-08-25      4344   50.806217   Inlier\n237 2023-08-26      4473   50.413101   Inlier\n238 2023-08-27      4588   52.260876   Inlier\n239 2023-08-28      4399   51.222641   Inlier\n240 2023-08-29      4666   49.259281   Inlier\n241 2023-08-30      4262   50.480923   Inlier\n242 2023-08-31      4327   50.072197   Inlier\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipykernel_29249/4146885998.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  test_data['Anomaly'] = predictions\n/tmp/ipykernel_29249/4146885998.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  test_data['Anomaly'] = test_data['Anomaly'].map({-1: 'Outlier', 1: 'Inlier'})\n"]}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"64ddb7ac-61a8-4f35-b86e-92dfc79a26cc"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"widgets":{},"spark_compute":{"compute_id":"/trident/default"},"trident":{"lakehouse":{"default_lakehouse":"ee911489-4713-4e55-aedb-ebc5e3235b6b","default_lakehouse_name":"Hackathon","default_lakehouse_workspace_id":"4c4664f3-622d-4959-933a-efeec33fe813"}}},"nbformat":4,"nbformat_minor":5}