{"cells":[{"cell_type":"markdown","id":"f5f8b248-2972-4df4-ad7f-3e2d4128d9ba","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### Install packages"]},{"cell_type":"code","execution_count":null,"id":"654c69a2-bdc8-4dbd-855a-7be96041d672","metadata":{},"outputs":[],"source":["%pip install openai==1.12.0\n","%pip install pycountry"]},{"cell_type":"markdown","id":"b1f6884c-2f65-4e60-98ca-2afd61b53ba1","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### Required packages"]},{"cell_type":"code","execution_count":null,"id":"23ae6e46-de9c-4069-b2af-7904b67142b6","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["import openai\n","from openai import AzureOpenAI\n","import json\n","import random\n","import pycountry"]},{"cell_type":"markdown","id":"3899873d-527a-4433-8de4-0e1fe17c6a21","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### Set up Azure OpenAI connection\n","###### Reference: https://community.fabric.microsoft.com/t5/Hack-Together/Fabric-cant-import-AzureOpenAI/m-p/3703267#M66"]},{"cell_type":"code","execution_count":null,"id":"e25c2a4b-6db7-4736-b0e7-a0030cca9652","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["client = AzureOpenAI(\n","    # Include endpoint - for the competition it was https://polite-ground-030dc3103.4.azurestaticapps.net/api/v1\n","    azure_endpoint=\"ADD ENDPOINT\",\n","    api_key=\"YOUR API KEY\",  # Add API KEY\n","    api_version=\"2023-09-01-preview\",\n",")"]},{"cell_type":"markdown","id":"995a39e2-cb12-406d-845a-a56e55a5aacb","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### Create prompt"]},{"cell_type":"code","execution_count":null,"id":"4f4729f6-455a-481f-bbbb-306b31c9d853","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Prompt is a combination of 3 parts:\n","\n","# Prompt text\n","prompt_text = \"Can you create the dataframes detailed below:\"\n","\n","# Data_specs_JSON string\n","data_specs_file_path = r\"/lakehouse/default/Files/Data_Specs.txt\"\n","with open(data_specs_file_path, 'r') as file:\n","    data_specs_content = file.read()\n","data_specs = f\"data_specs_details = json.loads({json.dumps(data_specs_content)})\"\n","\n","# Additional instructions - adjust as needed\n","additional_instructions = \"\"\"\n","Ensure these instructions are followed:\n","For the Fact table, use the IDs from the Dim_Product, Dim_Store, and Dim_Customer tables.\n","All columns within the arrays need to be the same length.\n","IDs should be unique in the dimension dataframes, but can be repeated in the fact table.\n","Dates can be repeated in the fact table, so all columns from the array are of the same length.\n","Only provide the python code in your response, if there are any comments, please wrap them as python comments using the # \n","Please create just the script, with no printing steps. The script should end when the dataframes get created \n","\"\"\"\n","\n","# Combine the 3 into a single text\n","PROMPT = f\"{prompt_text}\\n\\n{data_specs}\\n\\n{additional_instructions}\"\n","\n","print(PROMPT)"]},{"cell_type":"markdown","id":"94256722-a07e-4786-9f0d-738e95c098eb","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### Get AzureOpenAI response"]},{"cell_type":"code","execution_count":null,"id":"a3a7d109-44cd-4b8d-93e5-f3eb7026658b","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Run using AzureOpenAI - Select the model and temperature\n","MESSAGES = []\n","MESSAGES.append({\"role\": \"user\", \"content\": PROMPT})\n","completion = client.chat.completions.create(\n","    # model and temperature adjusted as suggested here: https://www.reddit.com/r/ChatGPTCoding/comments/12i6k06/best_temperature_for_gpt4_api_to_get_quality/\n","    model=\"gpt-35-turbo\", messages=MESSAGES, temperature=0.9)\n","code = completion.choices[0].message.content\n","print(code)"]},{"cell_type":"markdown","id":"2e5e85e0-25f0-41fa-a501-507fc3e4730c","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### Enhance response based on Script_Help file"]},{"cell_type":"code","execution_count":null,"id":"633f8e68-7d38-4acf-89ae-a5f910fc79a9","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Enhance code with Script_Help practices\n","\n","# Ensure your script file path is correct\n","script_file_path = \"/lakehouse/default/Files/Script_Help.txt\"\n","\n","# Read the script content into a variable\n","with open(script_file_path, 'r') as file:\n","    script_content = file.read()\n","\n","prompt_1 = \"\"\"\n","Can you enhance this code? \n","Only provide the python code in your response, if there are any comments, please wrap them as python comments using the # \n","Please create just the script, no printing steps. The script should end when the dataframes dictionary with all the dataframes get created \n","\"\"\"\n","prompt_2 = code\n","prompt_3 = \"using the details below:\"\n","prompt_4 = script_content\n","ADJUSTED_PROMPT = f\"{prompt_1}\\n\\n{prompt_2}\\n\\n{prompt_3}\\n\\n{prompt_4}\"\n","\n","print(ADJUSTED_PROMPT)"]},{"cell_type":"markdown","id":"87b13843-5d07-43f3-9e25-e6abafe33b44","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### Get Final Response"]},{"cell_type":"code","execution_count":null,"id":"27bea6bc-3575-49cc-8dc4-6f40d16e84c3","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Run using AzureOpenAI - Select the model and temperature\n","MESSAGES = []\n","MESSAGES.append({\"role\": \"user\", \"content\": ADJUSTED_PROMPT})\n","completion = client.chat.completions.create(\n","    # model and temperature adjusted as suggested here: https://www.reddit.com/r/ChatGPTCoding/comments/12i6k06/best_temperature_for_gpt4_api_to_get_quality/\n","    model=\"gpt-35-turbo\", messages=MESSAGES, temperature=0.9)\n","adjusted_code = completion.choices[0].message.content\n","print(adjusted_code)"]},{"cell_type":"markdown","id":"393087b9-5df0-41bf-8d46-5619bb48ff9b","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### Execute code"]},{"cell_type":"code","execution_count":null,"id":"f42c7fc3","metadata":{},"outputs":[],"source":["exec(adjusted_code)"]},{"cell_type":"markdown","id":"6f9717a9-b8aa-4739-bdf0-ebeef15261ad","metadata":{"nteract":{"transient":{"deleting":false}}},"source":["### Create csv files and load to Lakehouse"]},{"cell_type":"code","execution_count":null,"id":"1e2dda7f-a2b0-473f-a2aa-c5a9e7c86884","metadata":{"jupyter":{"outputs_hidden":false,"source_hidden":false},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["# Assuming the 'dataframes' dictionary is already defined as per your snippet\n","for name, df in dataframes.items():\n","    # Construct the file path where the CSV will be saved\n","    file_path = f\"/lakehouse/default/Files/csv_files/{name}.csv\"\n","    # Save the DataFrame to CSV\n","    # Set index=False if you don't want to include the index in the CSV\n","    df.to_csv(file_path, index=False)\n","\n","print(\"CSV files have been saved or updated.\")"]}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Synapse PySpark","language":"Python","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"trident":{"lakehouse":{"default_lakehouse":"ee911489-4713-4e55-aedb-ebc5e3235b6b","default_lakehouse_name":"Hackathon","default_lakehouse_workspace_id":"4c4664f3-622d-4959-933a-efeec33fe813"}},"widgets":{}},"nbformat":4,"nbformat_minor":5}
